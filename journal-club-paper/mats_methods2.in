\subsection{Feature Localization}
For evaluation of the closed-loop active compensation during cooperatively
controlled needle insertions, we use two cameras to capture real-time
images of the needle tip and target within the robot workspace.
This is a suitable substitute for medical imaging, in fact the
compensation technique is not dependent on the modality of 
the medical image. The two cameras are placed orthogonal
to each other, and are run by a standalone
software application.

In the software application, we employed Farneb\"{a}ck's 
algorithm \cite{Gunnar2003} to execute on captured video frames
to localize the moving needle tip and obtain homogeneous
transformations of the tip and the target. We used a color
segmentation technique to demonstrate the active compensation.

\subsection{Active Compensation}

Before any targeting takes place, registration is performed by
rigidly attaching a marker to the robot. For example, we would
attach the marker with MR visible fiducials
when moving through an MRI machine. This is visually
supported by Figure \ref{reg-frames-fig}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.25]{registration-frames.png}
    \caption{Frames and transformations for image guidance registration}
    \label{reg-frames-fig}
\end{figure}

After the registration is complete, the marker is removed.
The OpenIGTLink \cite{Tokuda2009} communication protocol is used
to pass down the frame and transformations from image-guidance software
to the robot controller. As seen by Figure \ref{reg-frames-fig},
the transformation sequence 
${T^{Home}_{Pose}}^{-1} {T^{Home}_{Reg}}^{-1} {T^{Image}_{Reg}}^{-1}$
is used to express the registration with respect to the robot pose.