\subsection{Feature Localization}
For evaluation of the closed-loop active compensation during cooperatively
controlled needle insertions, we use two cameras to capture real-time
images of the needle tip and target within the robot workspace.
This is a suitable substitute for medical imaging, in fact the
compensation technique is not dependent on the modality of 
the medical image. The two cameras are placed orthogonal
to each other, and are run by a standalone
software application.

In the software application, we employed Farneb\"{a}ck's 
algorithm \cite{Gunnar2003} to execute on captured video frames
to localize the moving needle tip and obtain homogeneous
transformations of the tip and the target. We used a color
segmentation technique to demonstrate the active compensation.

\subsection{Active Compensation}

Before any targeting takes place, registration is performed by
rigidly attaching a marker to the robot. For example, we would
attach the marker with MR visible fiducials
when moving through an MRI machine. This is visually
supported by Figure \ref{reg-frames-fig}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.25]{registration-frames.png}
    \caption{Frames and transformations for image guidance registration}
    \label{reg-frames-fig}
\end{figure}

After the registration is complete, the marker is removed.
The OpenIGTLink \cite{Tokuda2009} communication protocol is used
to pass down the frame and transformations from image-guidance software
to the robot controller. As seen by Figure \ref{reg-frames-fig},
the transformation sequence 
${T^{Home}_{Pose}}^{-1} {T^{Home}_{Reg}}^{-1} {T^{Image}_{Reg}}^{-1}$
is used to express the registration with respect to the robot pose.

Throughout the insertion, the robot continuously receives the tip
and target locations with respect to the image. Using the
known transformation matrices, it determines the tip and target
with respect to the robot pose. Naturally it can then compute
the target location with respect to the tip, or $T^{Tip}_{Target}$.
This tells us our desired compensatory effort.

To achieve this compensatory effort in all the insertion trials 
of our work, we chose to use Gang Li's novel CURV model \cite{Li2016PhD},
where both magnitude and direction of the desired effort can be
implemented. Assume that $\theta$ is the current rotational angle
of the bevel, and $\theta_d$ is the desired angle of the bevel for
compensation. At any angular position, we can use the following equation.

\begin{equation} \label{ang-vel-eqn}
    \hat{\omega}(\theta, \theta_d) = 1 - \alpha e^{-\frac{(\theta-\theta_d)^2}{2c^2}}
\end{equation}

Equation \ref{ang-vel-eqn} gives the angular velocity as a function
of $\theta$ and $\theta_d$. Here, widening the Guassian width $c$
gives a bigger range of angles where rotation occurs below the nominal
velocity. Also, increasing the Guassian magnitude $\alpha$ leads to more
deflection in $\theta_d$. The authors of this synopsis recommend referencing
Gang Li's excellent disseration \cite{Li2016PhD} for the angular velocity profile
graph of CURV. While CURV was used in this work, it is possible to use other
bevel tip based curvature models.

To calculate the $\theta_d$ in our case, we used the $atan2$ function
on the $x$ and $y$ positions obtained from $T^{Tip}_{Target}$. We set
$c$ is Equation \ref{ang-vel-eqn} to $10\degree$ for all insertions. The
$\alpha$ was chosen as an intermediate curvature value by projecting the needle
tip orientation onto the target plane. For projecting the orientation,
we first found the Euler angle rotation about the x and y axes, and then
used the following equations,

\begin{equation}
    X_{projected} = D_i \times \arctan(Rot(y))
\end{equation}

\begin{equation}
    Y_{projected} = D_i \times \arctan(Rot(x))
\end{equation}

Where $D_i$ is the remaining insertion depth.

